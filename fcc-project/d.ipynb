{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAGIC Gamma Telescope Analysis\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "This dataset consists of Monte Carlo (MC) generated data simulating high-energy gamma particle registration in a Cherenkov gamma telescope using imaging techniques. The telescope detects gamma rays by capturing the Cherenkov radiation emitted by charged particles formed in electromagnetic showers initiated by gamma interactions in the atmosphere.\n",
    "\n",
    "The recorded data include pulses from Cherenkov photons impacting the photomultiplier tubes arranged in a plane (the camera). Depending on the gamma energy, anywhere from a few hundred to 10,000 photons are collected, forming a shower image that helps distinguish between gamma-initiated showers (signal) and hadronic showers caused by cosmic rays (background).\n",
    "\n",
    "After pre-processing, the shower image generally appears as an elongated cluster, with its long axis pointing toward the camera center if the telescope is aligned with a point source. A principal component analysis (PCA) is performed to determine correlation axes and define an ellipse, aiding in classification. Features such as Hillas parameters, asymmetry along the major axis, and cluster extent further assist in discrimination.\n",
    "\n",
    "The data was produced by the Monte Carlo simulation program Corsika, detailed in:\n",
    "\n",
    "D. Heck et al., CORSIKA: A Monte Carlo Code to Simulate Extensive Air Showers, Forschungszentrum Karlsruhe FZKA 6019 (1998).\n",
    "http://rexa.info/paper?id=ac6e674e9af20979b23d3ed4521f1570765e8d68\n",
    "\n",
    "Simulation parameters enabled the detection of events with **energies below 50 GeV**\n",
    "\n",
    "**Source:** [UCI Machine Learning Repository - MAGIC Gamma Telescope](https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"class\"]\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/usernameneo/Data-Science-Projects/refs/heads/day-II/fcc-project/magic04.data?token=GHSAT0AAAAAADEBRHU436LOFW5OQM3BDD2M2BITYGA\"\n",
    "df = pd.read_csv(url, names=cols)\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Class Values\n",
    "The only class values are either \"g\" for gamma particles or \"h\" for hadron particles. We will convert these to binary values: 0 for hadrons and 1 for gamma particles to assist in computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique class values\n",
    "print(\"Unique class values:\", df[\"class\"].unique())\n",
    "\n",
    "# Convert class labels to binary (0 for hadron 'h', 1 for gamma 'g')\n",
    "df[\"class\"] = (df[\"class\"] == \"g\").astype(int)\n",
    "\n",
    "# Display the updated dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Let's visualize the distribution of each feature for both gamma and hadron particles to understand the differences between the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for each feature, comparing gamma and hadron particles\n",
    "for col in cols[:-1]:  # Exclude the 'class' column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df[df[\"class\"]==1][col], color=\"blue\", label=\"Gamma-Ray Particles\", alpha=0.7, density=True)\n",
    "    plt.hist(df[df[\"class\"]==0][col], color=\"red\", label=\"Hadronic Particles\", alpha=0.7, density=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(col)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting and Preprocessing\n",
    "\n",
    "### Train, Validation and Test Datasets\n",
    "We'll split the data into training (60%), validation (20%), and test (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train, val, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and Oversampling Function\n",
    "We'll create a function to standardize features and optionally oversample the minority class to handle class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(dataframe, oversample=False):\n",
    "    X = dataframe[dataframe.columns[:-1]].values\n",
    "    y = dataframe[dataframe.columns[-1]].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    if oversample:\n",
    "        ros = RandomOverSampler()\n",
    "        X, y = ros.fit_resample(X, y)\n",
    "\n",
    "    data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
    "    return data, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Class Distribution in Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution before oversampling\n",
    "print(\"Before oversampling:\")\n",
    "print(\"Gamma:\", len(train[train[\"class\"]==1]))\n",
    "print(\"Hadron:\", len(train[train[\"class\"]==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Scaling and Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling and oversampling to training set, only scaling to validation and test sets\n",
    "train, X_train, y_train = scale_dataset(train, oversample=True)\n",
    "val, X_val, y_val = scale_dataset(val, oversample=False)\n",
    "test, X_test, y_test = scale_dataset(test, oversample=False)\n",
    "\n",
    "# Check class distribution after oversampling\n",
    "print(\"After oversampling:\")\n",
    "print(\"Total:\", len(y_train))\n",
    "print(\"Gamma:\", sum(y_train==1))\n",
    "print(\"Hadron:\", sum(y_train==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model: K-Nearest Neighbors\n",
    "\n",
    "We'll implement a K-Nearest Neighbors classifier to distinguish between gamma and hadron particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create and train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predicts = knn_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Interpretation\n",
    "\n",
    "The classification report shows:\n",
    "- **Class 0 (Hadron particles)**: Precision: 76%, Recall: 76%, F1-score: 76%\n",
    "- **Class 1 (Gamma particles)**: Precision: 87%, Recall: 87%, F1-score: 87%\n",
    "- **Overall Accuracy**: 83%\n",
    "\n",
    "The model performs better at identifying gamma particles than hadron particles, which is expected given the nature of the features and the physical differences between the two types of particles. The 83% accuracy suggests the model is reasonably effective at distinguishing between gamma and hadron particles based on the Cherenkov telescope measurements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}